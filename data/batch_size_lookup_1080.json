{
"bert-base-uncased": 8,
"bert-large-uncased": 4,
"distilbert-base-uncased": 16,
"roberta-base": 8,
"roberta-large": 4,
"distilroberta-base": 16,
"xlm-roberta-base": 4,
"albert-base-v2": 16,
"albert-large-v2": 4,
"google/electra-base-generator": 16,
"google/electra-large-generator": 16,
"bert-base-multilingual-uncased": 8,
"GroNLP/hateBERT": 16,
"Twitter/twhin-bert-base": 2,
"Twitter/twhin-bert-large": 1,
"xlm-roberta-large": 1,
"medicalai/ClinicalBERT": 16,
"dbmdz/bert-base-historic-multilingual-cased": 16,
"Davlan/afro-xlmr-large": 4,
"albert-xlarge-v2": 2,
"albert-xxlarge-v2": 1,
"bert-large-uncased-whole-word-masking": 4,
"Geotrend/bert-base-en-cased": 16,
"Geotrend/bert-base-10lang-cased": 16,
"Geotrend/bert-base-15lang-cased": 16,
"Intel/bert-base-uncased-sparse-70-unstructured": 16,
"Intel/bert-base-uncased-sparse-85-unstructured-pruneofa": 16,
"Intel/bert-base-uncased-sparse-90-unstructured-pruneofa": 16,
"Intel/distilbert-base-uncased-sparse-85-unstructured-pruneofa": 16,
"Intel/distilbert-base-uncased-sparse-90-unstructured-pruneofa": 16,
"abhi1nandy2/Bible-roberta-base": 16,
"cardiffnlp/twitter-roberta-base-irony": 16,
"distilbert-base-uncased-finetuned-sst-2-english": 16,
"roberta-large-openai-detector": 4,
"roberta-base-openai-detector": 8,
"tomh/toxigen_roberta": 8,
"gpt2": 1,
"openai-gpt": 1,
"gpt2-large": 1,
"xlnet-base-cased": 8,
"xlnet-large-cased": 4
}
